manifest {
    description = 'zUMIs'
    mainScript = 'main.nf'
}

params {

    // Slurm Parameters 

    userID = "c.c1430759"
    userProjectCode = "scw1557"

    sleepTimeStart = '0m'
    sleepTimeEnd = '0m'
    retries = '5'

  executor {
    queueSize = 40
    submitRateLimit = '1 sec'
  }

// Basic zUMIs options

    // Project Information

    projectName = "PBMC_10k"
    projectDir = "/scratch/${userID}/scRNAseq-zUMIs/"
    
    // Input/Output/Resources

    binDir = "bin/" //script directory
    inputDir = "input/" //iput directory
    outputDir = "output/" //output directory
    resourcesDir = "resources/" //resources directory
    
    input_csv = "${params.projectDir}${inputDir}input.csv" //path to input csv file liting fastq sample files and their base definition
    
    read_length = 90 // read length - used to determine sjdboverhang in STAR

    // Genome resource files
    genomeName = "Homo_sapiens.GRCh38" 
    fastaName = "Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa"
    gtfName = "Homo_sapiens.GRCh38.104.chr.gtf"
    genome = "/home/${userID}/resources/genomes/human/hg38/${fastaName}.gz"
    gtf = "/home/${userID}/resources/genomes/human/hg38/${gtfName}.gz"

    // Advanced zUMIs options
    
    // Reference genome options

    exon_extension = "FALSE" // extend exons? T/F
    extension_length = 0 // Length of exon extension in BP
    scaffold_length_min = 0 // Minimum length of sequence contig for mappedreads to be counted (0 = all contigs)

    // Filter Cutoffs

    // Barcode Filter
    BC_num_bases = "1" // maximum number of bases allowed below minimum phred score
    BC_phred = "20" // minimum phred score

    // UMI Filter
    UMI_num_bases = "1" // maximum number of bases allowed below minimum phred score
    UMI_phred = "20" // minimum phred score

    // Barcode Options

    barcode_file = null // optional barcode whitelist file containing list of known BCs 
    barcode_num = null // Number of barcodes to retain - null if automatic BC detection
    barcode_automatic = "TRUE" // Run automatic BC dtection? T/F
    barcode_sharing = null // path to file containing associated barcodes where multiple barcodes = 1 cell
    barcode_binning = 1 // hamming distance used for binning similar barcodes
    n_reads_per_cell = 100 // minimum number of read required for barcode to be kept
    demultiplex = "FALSE" // produce demultiplexed bam files? T/F

    // Counting Options

    include_introns = "TRUE" // Count inton mapped reads? T/F
    intron_probability = "TRUE" // calculate probability of intron mapped reads coming from mtRNA
    downsampling = 0 // nreads to downsample to (0=adaptive)
    strand = 1 // stranding of cDNA (0 = unstranded, 1 = +ve, 2 = -ve)
    ham_dist = 1 // hamming distance used to bin similar UMI sequences.
    primary_hit = "TRUE" // Count primary hit for multimapping reads
    multi_overlap = "TRUE" // count reads overlapping multiple features
    fraction_overlap = 0 // minimum amount of overlapping sequence with feature (as fraction of read) for read to be counted
    two_pass = "TRUE" // perform two pass star mapping

    // Mapping

    additional_STAR_params = "NONE" // additional parameters passed to star mapping command
    additional_fq = "NONE" // additional reference fastq files

    // Statistical Outputs and Plots

    make_stats: "TRUE" //produce summary statistics
    loompy = true // produce loom output
    velocyto = true // run RNA velocity calculation
    
    // Memory/Threading

    num_threads = 32 // cores requested by SBATCH
    mem_limit = 100 // memory assigned to processes

}
// sbatch parameters
process {
    executor = "slurm"
    queue = "htc" // compute partition
    clusterOptions = "-A ${params.userProjectCode}"
}

// log file output directory
params.logDir = "${params.projectDir}${params.outputDir}${params.projectName}_logs"
//process executed after every process to collate log files
process.afterScript = {
    collectLogsDir = params.logDir

    collectLogsDir = workflow.launchDir.resolve(collectLogsDir).toString()
    if (!collectLogsDir.matches("^/.*")) collectLogsDir = workflow.launchDir.toString() + "/log"


    // Use process name to build log sub-directories
    logSubDir = task.name.replace(" (null)", "").replace(" ", "/").replaceAll(" ", "_").replaceAll("[()]", "")
    logDirectory = collectLogsDir + "/" + logSubDir

    // Complete Process:
    cmd = "ls -alR --full-time > .command.ls; " //print list of all files in process directory to additional logfile
    cmd += "mkdir .log_files; " //create hidden log file directorry within nextflow process directory
    cmd += "for file in .command.*; do cp -a \${file} .log_files/\${file#.}.txt; done; " //copy log files into hidden directory with .txt suffix
    cmd += "cd .log_files; "  //enter hidden log directory
    cmd += "mkdir -p ${logDirectory}; cp -a *.txt ${logDirectory}; " //copy all files to process log directory stored within log directory, itself within output directory
    cmd += "cd ..;" //return to process directory
    cmd
}
// nextflow work directory location
workDir = "${params.projectDir}work"
// cleanup nextflow work direction after completion of script
cleanup = true
// containerisation
process.container = 'scRNA-seq.sif' // name of/path to container
singularity.enabled = true // use singularity container